---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I work at [Zhejiang Lab](https://zhejianglab.cn/com) as an Associate Researcher now in Hangzhou, leading a fundamental computer vision/machine learning research group. I completed my Ph.D. in College of Computer Science from Zhejiang University, co-supervised by Prof. [Yueting Zhuang (Â∫ÑË∂äÊå∫)](https://scholar.google.com/citations?user=1RD7UJAAAAAJ&hl=zh-CN) and Prof. [Donghui Wang (Áéã‰∏úËæâ)](https://scholar.google.com/citations?user=AkRWtMUAAAAJ&hl=zh-CN). I am now working on zero/few-shot learning, open-world learning, long-tailed recognition etc. If you are seeking any form of **academic cooperation**, please feel free to email me at [liyn@zhejianglab.com](mailto:liyn@zhejianglab.com) or [ynli.zju@gmail.com](mailto:ynli.zju@gmail.com). 




# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/cvpr24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


The Neglected Tails of Vision-Language Models

Shubham Parashar, Zhiqiu Lin, Tian Liu, Xiangjue Dong, **Yanan Li**, Deva Ramanan, James Caverlee, Shu Kong

[[**Project**]](https://shubhamprshr27.github.io/neglected-tails-of-vlms/) &nbsp;&nbsp; [[Paper]](https://arxiv.org/pdf/2401.12425.pdf)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/neurips23-insdet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


A High-Resolution Dataset for Instance Detection with Multi-View Object Capture
Qianqian Shen, Yunhan Zhao, Nahyun Kwon, Jeeeun Kim, **Yanan Li<sup>*</sup>**, Shu Kong<sup>*</sup>
[[**Project**]](https://github.com/insdet/instance-detection/) &nbsp;&nbsp; [[Paper]](https://arxiv.org/pdf/2310.19257)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<!-- - This paper proposes the first large-scale instance detection dataset. -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/emnlp23.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Prompting Scientific Names for Zero-Shot Species Recognition

Shubham Parashar, Zhiqiu Lin, **Yanan Li<sup>*</sup>**, Shu Kong<sup>*</sup>

[[Paper]](https://aclanthology.org/2023.emnlp-main.610.pdf)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<!-- - This paper proposes the first large-scale instance detection dataset. -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022</div><img src='images/neurips22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Alleviating the Sample Selection Bias in Few-Shot Learning by Removing Projection to the Centroid

Jing Xu, Xu Luo, Xinglin Pan, **Yanan Li**, Wenjie Pei, Zenglin Xu

[[Paper]](https://proceedings.neurips.cc/paper_files/paper/2022/file/84b686f7cc7b7751e9aaac0da74f755a-Paper-Conference.pdf)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2021</div><img src='images/aaai21.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Inference Fusion with Associative Semantics for Unseen Object Detection

**Yanan Li**, Pengyang Li, Han Cui, Donghui Wang

[[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/16295)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2020</div><img src='images/ijcai20.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Dress Like an Internet Celebrity: Fashion Retrieval in Videos

Hongrui Zhao, Jin Yu, **Yanan Li**, Donghui Wang<sup>*</sup>, Jie Liu, Hongxia Yang, Fei Wu

[[Paper]](https://www.ijcai.org/Proceedings/2020/0147.pdf)
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
